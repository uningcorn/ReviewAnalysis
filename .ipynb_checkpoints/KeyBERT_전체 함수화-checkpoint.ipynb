{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d5250f6-ada3-4b34-89da-d7a5b8a1dcf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HWAN\\anaconda3\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\HWAN\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keybert import KeyBERT\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import Counter\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "# Okt 형태소 분석기 초기화\n",
    "okt = Okt()\n",
    "\n",
    "# 불용어 리스트\n",
    "stop_words = ['좋다', '입다', '같다', '이다', '있다', '입']\n",
    "\n",
    "# 전처리 함수 정의\n",
    "def clean_review_column(df, column_name):\n",
    "    df[column_name] = df[column_name].str.replace('\\n', ' ', regex=False)  # 개행 문자 제거\n",
    "    df[column_name] = df[column_name].str.replace(r'[ㄱ-ㅎㅏ-ㅣ]+', ' ', regex=True)  # 한글 자모 제거\n",
    "    df[column_name] = df[column_name].str.replace(r'[^\\w\\s]', ' ', regex=True)  # 구두점 제거\n",
    "    df[column_name] = df[column_name].str.replace(r'\\s+', ' ', regex=True)  # 여러 공백을 한 칸으로 변환\n",
    "    return df\n",
    "\n",
    "# 키워드 원형 변환 함수\n",
    "def lemmatize_keyword(keyword):\n",
    "    morphs = okt.pos(keyword, stem=True)  # 형태소 분석 및 어간 추출\n",
    "    lemmatized = [word for word, pos in morphs if pos in ['Noun', 'Verb', 'Adjective']]  # 명사, 동사, 형용사만 추출\n",
    "    return ' '.join(lemmatized) if lemmatized else None  # 원형 변환된 단어들을 합침, 없으면 None 반환\n",
    "\n",
    "# 핵심 키워드 추출 함수 정의 (KeyBERT)\n",
    "def extract_keywords(text):\n",
    "    kw_model = KeyBERT()  # KeyBERT 모델 초기화\n",
    "    vectorizer = CountVectorizer(ngram_range=(1, 1))  # 단일 단어 추출\n",
    "    keywords = kw_model.extract_keywords(text, vectorizer=vectorizer, top_n=5)  # 상위 5개의 키워드 추출\n",
    "    return keywords\n",
    "\n",
    "# 전체 리뷰에서 키워드 추출 및 처리\n",
    "def process_keywords(df, review_column):\n",
    "    # 전처리\n",
    "    df = clean_review_column(df, review_column)\n",
    "    documents = df[review_column]\n",
    "\n",
    "    # 각 리뷰에 대해 핵심 키워드 추출\n",
    "    df['Keywords'] = documents.apply(extract_keywords)\n",
    "\n",
    "    # 키워드를 모두 모아서 리스트로 풀기\n",
    "    all_keywords = []\n",
    "    for keywords in df['Keywords']:\n",
    "        for keyword, score in keywords:\n",
    "            lemmatized_keyword = lemmatize_keyword(keyword)\n",
    "            if lemmatized_keyword and lemmatized_keyword not in stop_words:  # 불용어 필터링\n",
    "                all_keywords.append(lemmatized_keyword)\n",
    "\n",
    "    # 각 키워드의 빈도를 계산하고 상위 10개의 키워드 추출\n",
    "    keyword_counts = Counter(all_keywords)\n",
    "    top_10_keywords = keyword_counts.most_common(10)\n",
    "\n",
    "    # 키워드만 리스트로 변환\n",
    "    top_10_keywords_list = [keyword for keyword, _ in top_10_keywords]\n",
    "    keywords_str = ', '.join(top_10_keywords_list)\n",
    "\n",
    "    return keywords_str\n",
    "\n",
    "# 데이터프레임에 새로운 행을 추가하는 함수\n",
    "def add_to_dataframe(df, csv_title, keywords_str):\n",
    "    new_row = pd.DataFrame({'title': [csv_title], 'keyword': [keywords_str]})\n",
    "    df = pd.concat([df, new_row], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "# 전체 워크플로우 함수\n",
    "def process_csv_file(csv_file, csv_title, df):\n",
    "    # CSV 파일 읽기\n",
    "    new_df = pd.read_csv(csv_file)\n",
    "\n",
    "    # 상위 10개 키워드 추출\n",
    "    keywords_str = process_keywords(new_df, 'Review')\n",
    "\n",
    "    # 데이터프레임에 새로운 데이터 추가\n",
    "    df = add_to_dataframe(df, csv_title, keywords_str)\n",
    "    return df\n",
    "\n",
    "# 초기 데이터프레임 생성 (첫 CSV 처리)\n",
    "csv_title = \"[SET] 워셔블 케이블 반팔 니트 세트\"\n",
    "csv_file = \"[SET] 워셔블 케이블 반팔 니트 세트.csv\"\n",
    "df = pd.DataFrame(columns=['title', 'keyword'])  # 빈 데이터프레임 생성\n",
    "df = process_csv_file(csv_file, csv_title, df)\n",
    "\n",
    "# 이후 새로운 CSV 파일을 처리할 때\n",
    "# 새로운 CSV 파일과 제목을 추가할 수 있습니다.\n",
    "# 예시:\n",
    "# new_csv_title = \"새로운 제품 제목\"\n",
    "# new_csv_file = \"새로운 파일 경로.csv\"\n",
    "# df = process_csv_file(new_csv_file, new_csv_title, df)\n",
    "\n",
    "# 데이터프레임 저장\n",
    "# df.to_csv('output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "664541a0-bde2-44cc-9035-d0dc426a8eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[SET] 워셔블 케이블 반팔 니트 세트</td>\n",
       "      <td>사이즈, 색감, 여름, 가성 비, 재질, 가격, 배송, 니트, 만족하다, 시원하다</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    title                                        keyword\n",
       "0  [SET] 워셔블 케이블 반팔 니트 세트  사이즈, 색감, 여름, 가성 비, 재질, 가격, 배송, 니트, 만족하다, 시원하다"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52af2f21-cb31-4547-9c66-90194199265e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fdedd8-96e7-4fae-b56f-0e705b2b8056",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dce3b8-7865-4c4a-82e8-d7e3202df1cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0518d9fc-9c7a-4b8b-850d-041a990b90ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37b1f094-2508-4186-bbcc-c315bd5fdd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 코드 정의\n",
    "def clean_review_column(df, column_name):\n",
    "    # '\\n'을 제거하고 한글 자모 및 구두점 제거\n",
    "    df[column_name] = df[column_name].str.replace('\\n', ' ', regex=False)  # 개행 문자 제거\n",
    "    df[column_name] = df[column_name].str.replace(r'[ㄱ-ㅎㅏ-ㅣ]+', ' ', regex=True)  # 한글 자모 제거\n",
    "    df[column_name] = df[column_name].str.replace(r'[^\\w\\s]', ' ', regex=True)  # 특정 구두점 제거\n",
    "    \n",
    "    # 여러 공백을 한 칸으로 변환\n",
    "    df[column_name] = df[column_name].str.replace(r'\\s+', ' ', regex=True)  # 여러 개의 공백을 한 칸으로 변환\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5a419f2-65b8-4dc7-b191-e6a0e7420cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('[SET] 워셔블 케이블 반팔 니트 세트.csv')\n",
    "df = clean_review_column(df, 'Review')\n",
    "documents = df['Review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0566a08b-02b1-481f-b276-5eddb985e918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      여름에 꼭 가지고 있어야 템 중 하나 입니다 원플원임에도 불구하고 퀄리티랑 핏이 너...\n",
       "1                   여름에 입기 딱 좋은 두께에요 부드러워서 맨 몸에 입어도 괜찮아요\n",
       "2      시원한 느낌이라 좋습니다 부드러워 편하네요 카라와 단추 라인이 예쁘게 잘 나왔습니다...\n",
       "3      무신사 매장까지 방문해서 재질확인후이 구매하였습니다 여름에 입기 좋은 두께감입니다 ...\n",
       "4         최고에요 사이즈 살짝 오버핏인데 그냥 너무 좋야요 제 스펙이랑 비슷하시면 m 사세요\n",
       "                             ...                        \n",
       "885                          합리적인 가격이고 여름 반팔은 역시나 수아레네요 \n",
       "886                         옷 2벌 와요 선택하실때 다른거로 선택하시길 바래요\n",
       "887           약간 큰 느낌이긴 한데 이 가격에 이정도면 무난 합니다 한여름에는 힘들듯해요\n",
       "888                      사이즈도 좋고 여름에 잘 입고 다니고 있습니다 추천합니다\n",
       "889                       가성비 젛아요 품은 생각보다 좀 커요 참고하세요 이뻐요\n",
       "Name: Review, Length: 890, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdf245b0-0b9f-42ea-a6f0-90cfed722229",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HWAN\\anaconda3\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\HWAN\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "                                              Review  \\\n",
      "0  여름에 꼭 가지고 있어야 템 중 하나 입니다 원플원임에도 불구하고 퀄리티랑 핏이 너...   \n",
      "1               여름에 입기 딱 좋은 두께에요 부드러워서 맨 몸에 입어도 괜찮아요   \n",
      "2  시원한 느낌이라 좋습니다 부드러워 편하네요 카라와 단추 라인이 예쁘게 잘 나왔습니다...   \n",
      "3  무신사 매장까지 방문해서 재질확인후이 구매하였습니다 여름에 입기 좋은 두께감입니다 ...   \n",
      "4     최고에요 사이즈 살짝 오버핏인데 그냥 너무 좋야요 제 스펙이랑 비슷하시면 m 사세요   \n",
      "\n",
      "                                            Keywords  \n",
      "0  [(정사이즈로, 0.3535), (구매하시면, 0.3386), (구매하시거나, 0....  \n",
      "1  [(입어도, 0.6102), (부드러워서, 0.4709), (여름에, 0.4678)...  \n",
      "2  [(적당히, 0.6256), (라인이, 0.6139), (시원한, 0.6104), ...  \n",
      "3  [(재질확인후이, 0.7081), (방문해서, 0.6456), (무신사, 0.594...  \n",
      "4  [(스펙이랑, 0.6513), (사이즈, 0.5276), (사세요, 0.4755),...  \n"
     ]
    }
   ],
   "source": [
    "from keybert import KeyBERT\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# KeyBERT 모델 초기화\n",
    "kw_model = KeyBERT()\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1))\n",
    "\n",
    "# 각 문서에서 핵심 키워드 추출\n",
    "def extract_keywords(text):\n",
    "    # 각 텍스트에서 상위 5개의 키워드 추출\n",
    "    keywords = kw_model.extract_keywords(text, vectorizer=vectorizer, top_n=5)\n",
    "    return keywords\n",
    "\n",
    "# 전체 문서에 대해 핵심 키워드 추출\n",
    "df['Keywords'] = documents.apply(extract_keywords)\n",
    "\n",
    "# 키워드가 잘 추출되었는지 확인\n",
    "print(df[['Review', 'Keywords']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce37629c-0d0d-4c62-8a1a-93e3927c70e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Star</th>\n",
       "      <th>Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>여름에 꼭 가지고 있어야 템 중 하나 입니다 원플원임에도 불구하고 퀄리티랑 핏이 너...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[(정사이즈로, 0.3535), (구매하시면, 0.3386), (구매하시거나, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>여름에 입기 딱 좋은 두께에요 부드러워서 맨 몸에 입어도 괜찮아요</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[(입어도, 0.6102), (부드러워서, 0.4709), (여름에, 0.4678)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>시원한 느낌이라 좋습니다 부드러워 편하네요 카라와 단추 라인이 예쁘게 잘 나왔습니다...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[(적당히, 0.6256), (라인이, 0.6139), (시원한, 0.6104), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>무신사 매장까지 방문해서 재질확인후이 구매하였습니다 여름에 입기 좋은 두께감입니다 ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[(재질확인후이, 0.7081), (방문해서, 0.6456), (무신사, 0.594...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>최고에요 사이즈 살짝 오버핏인데 그냥 너무 좋야요 제 스펙이랑 비슷하시면 m 사세요</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[(스펙이랑, 0.6513), (사이즈, 0.5276), (사세요, 0.4755),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>합리적인 가격이고 여름 반팔은 역시나 수아레네요</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[(합리적인, 0.6039), (가격이고, 0.5589), (반팔은, 0.4801)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>옷 2벌 와요 선택하실때 다른거로 선택하시길 바래요</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[(선택하시길, 0.6377), (2벌, 0.521), (다른거로, 0.5048),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>약간 큰 느낌이긴 한데 이 가격에 이정도면 무난 합니다 한여름에는 힘들듯해요</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[(한여름에는, 0.6743), (무난, 0.6062), (합니다, 0.5799),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>사이즈도 좋고 여름에 잘 입고 다니고 있습니다 추천합니다</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[(추천합니다, 0.8154), (다니고, 0.6586), (사이즈도, 0.6375...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>가성비 젛아요 품은 생각보다 좀 커요 참고하세요 이뻐요</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[(참고하세요, 0.6479), (가성비, 0.6211), (생각보다, 0.5426...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>890 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Review  Star  \\\n",
       "0    여름에 꼭 가지고 있어야 템 중 하나 입니다 원플원임에도 불구하고 퀄리티랑 핏이 너...   5.0   \n",
       "1                 여름에 입기 딱 좋은 두께에요 부드러워서 맨 몸에 입어도 괜찮아요   5.0   \n",
       "2    시원한 느낌이라 좋습니다 부드러워 편하네요 카라와 단추 라인이 예쁘게 잘 나왔습니다...   5.0   \n",
       "3    무신사 매장까지 방문해서 재질확인후이 구매하였습니다 여름에 입기 좋은 두께감입니다 ...   5.0   \n",
       "4       최고에요 사이즈 살짝 오버핏인데 그냥 너무 좋야요 제 스펙이랑 비슷하시면 m 사세요   5.0   \n",
       "..                                                 ...   ...   \n",
       "885                        합리적인 가격이고 여름 반팔은 역시나 수아레네요    5.0   \n",
       "886                       옷 2벌 와요 선택하실때 다른거로 선택하시길 바래요   5.0   \n",
       "887         약간 큰 느낌이긴 한데 이 가격에 이정도면 무난 합니다 한여름에는 힘들듯해요   5.0   \n",
       "888                    사이즈도 좋고 여름에 잘 입고 다니고 있습니다 추천합니다   5.0   \n",
       "889                     가성비 젛아요 품은 생각보다 좀 커요 참고하세요 이뻐요   4.0   \n",
       "\n",
       "                                              Keywords  \n",
       "0    [(정사이즈로, 0.3535), (구매하시면, 0.3386), (구매하시거나, 0....  \n",
       "1    [(입어도, 0.6102), (부드러워서, 0.4709), (여름에, 0.4678)...  \n",
       "2    [(적당히, 0.6256), (라인이, 0.6139), (시원한, 0.6104), ...  \n",
       "3    [(재질확인후이, 0.7081), (방문해서, 0.6456), (무신사, 0.594...  \n",
       "4    [(스펙이랑, 0.6513), (사이즈, 0.5276), (사세요, 0.4755),...  \n",
       "..                                                 ...  \n",
       "885  [(합리적인, 0.6039), (가격이고, 0.5589), (반팔은, 0.4801)...  \n",
       "886  [(선택하시길, 0.6377), (2벌, 0.521), (다른거로, 0.5048),...  \n",
       "887  [(한여름에는, 0.6743), (무난, 0.6062), (합니다, 0.5799),...  \n",
       "888  [(추천합니다, 0.8154), (다니고, 0.6586), (사이즈도, 0.6375...  \n",
       "889  [(참고하세요, 0.6479), (가성비, 0.6211), (생각보다, 0.5426...  \n",
       "\n",
       "[890 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "721d0da5-ddc4-4c9b-b4e8-497dd31548e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "상위 15개의 키워드:\n",
      "너무: 91번\n",
      "입기: 60번\n",
      "가성비: 49번\n",
      "좋아요: 46번\n",
      "여름에: 44번\n",
      "사이즈도: 44번\n",
      "만족합니다: 41번\n",
      "색감도: 39번\n",
      "입고: 35번\n",
      "생각보다: 34번\n",
      "사이즈: 30번\n",
      "마음에: 28번\n",
      "입을: 27번\n",
      "재질도: 27번\n",
      "좋고: 27번\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# 각 문서에서 추출된 키워드를 모은 리스트 생성\n",
    "all_keywords = []\n",
    "\n",
    "for keywords in df['Keywords']:\n",
    "    # keywords는 [(단어, 가중치), (단어, 가중치), ...] 형식이므로 단어만 추출\n",
    "    all_keywords.extend([keyword[0] for keyword in keywords])\n",
    "\n",
    "# 키워드의 빈도 계산\n",
    "keyword_counts = Counter(all_keywords)\n",
    "\n",
    "# 빈도 상위 10개의 키워드 출력\n",
    "top_keywords = keyword_counts.most_common(15)\n",
    "\n",
    "# 상위 10개의 키워드와 그 빈도를 출력\n",
    "print(\"상위 15개의 키워드:\")\n",
    "for word, count in top_keywords:\n",
    "    print(f\"{word}: {count}번\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9cc5186-b7c7-41ac-97d6-d4193e403e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('사이즈', 114), ('색감', 92), ('여름', 72), ('가성 비', 62), ('재질', 59), ('가격', 58), ('배송', 56), ('니트', 55), ('만족하다', 53), ('시원하다', 52)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "# Okt 형태소 분석기 초기화\n",
    "okt = Okt()\n",
    "\n",
    "stop_words = ['좋다', '입다', '같다', '이다', '있다', '입']\n",
    "\n",
    "# 키워드를 원형으로 변환\n",
    "def lemmatize_keyword(keyword):\n",
    "    morphs = okt.pos(keyword, stem=True)  # 형태소 분석 및 어간 추출\n",
    "    lemmatized = [word for word, pos in morphs if pos in ['Noun', 'Verb', 'Adjective']] # 명사, 동사, 형용사 추출\n",
    "    return ' '.join(lemmatized) if lemmatized else None  # 원형 변환된 단어들을 합침, 없으면 None 반환\n",
    "\n",
    "# 키워드를 모두 모아서 리스트로 풀기\n",
    "all_keywords = []\n",
    "for keywords in df['Keywords']:\n",
    "    # 키워드 원형으로 변환 후 리스트에 추가 (불용어 제외)\n",
    "    for keyword, score in keywords:\n",
    "        lemmatized_keyword = lemmatize_keyword(keyword)\n",
    "        if lemmatized_keyword and lemmatized_keyword not in stop_words:  # 불용어 필터링\n",
    "            all_keywords.append(lemmatized_keyword)\n",
    "\n",
    "# 각 키워드의 빈도를 계산\n",
    "keyword_counts = Counter(all_keywords)\n",
    "\n",
    "# 상위 10개의 키워드 추출\n",
    "top_10_keywords = keyword_counts.most_common(10)\n",
    "\n",
    "# 결과 출력\n",
    "print(top_10_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "deaf2ef0-885a-4d6b-b89c-731e2137a54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_title = \"[SET] 워셔블 케이블 반팔 니트 세트\"\n",
    "\n",
    "# 키워드만 추출하여 리스트로 변환\n",
    "top_10_keywords_list = [keyword for keyword, _ in top_10_keywords]\n",
    "\n",
    "keywords_str = ', '.join(top_10_keywords_list)\n",
    "\n",
    "# 데이터프레임 생성 (2열 1행: 'title'과 'keyword')\n",
    "df = pd.DataFrame({\n",
    "    'title': [csv_title],\n",
    "    'keyword': [keywords_str]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1f9e749-59a0-493e-beba-fd0ad349bb48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[SET] 워셔블 케이블 반팔 니트 세트</td>\n",
       "      <td>사이즈, 색감, 여름, 가성 비, 재질, 가격, 배송, 니트, 만족하다, 시원하다</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    title                                        keyword\n",
       "0  [SET] 워셔블 케이블 반팔 니트 세트  사이즈, 색감, 여름, 가성 비, 재질, 가격, 배송, 니트, 만족하다, 시원하다"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f8d51b-a0e2-4898-9eac-b84772977cd0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 유사도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff6dcaef-6012-44d6-95e6-50d1d5910621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('너무', 50.934399999999975), ('입기', 29.485300000000002), ('만족합니다', 29.198499999999996), ('가성비', 28.826499999999996), ('사이즈도', 27.499100000000002), ('색감도', 23.14320000000001), ('여름에', 20.394899999999996), ('생각보다', 19.092999999999996), ('입고', 18.4624), ('사이즈', 16.949499999999997)]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# 키워드와 유사도를 저장할 딕셔너리 초기화\n",
    "keyword_scores = defaultdict(float)\n",
    "\n",
    "# 키워드를 모두 모아서 유사도를 합산\n",
    "for keywords in df['Keywords']:\n",
    "    for keyword, score in keywords:\n",
    "        keyword_scores[keyword] += score  # 키워드에 유사도(score) 더하기\n",
    "\n",
    "# 유사도가 높은 상위 10개 키워드 추출\n",
    "top_10_keywords_with_scores = sorted(keyword_scores.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "# 결과 출력\n",
    "print(top_10_keywords_with_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56c5b554-2562-4038-abd7-f34e4792c86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('사이즈', 68.7178), ('색감', 54.8367), ('만족하다', 37.39309999999999), ('가성 비', 36.63450000000001), ('여름', 34.87310000000001), ('재질', 33.6559), ('배송', 32.547399999999996), ('가격', 32.340700000000005), ('시원하다', 30.535999999999994), ('니트', 29.453899999999997)]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "# Okt 형태소 분석기 초기화\n",
    "okt = Okt()\n",
    "\n",
    "stop_words = ['좋다', '입다', '같다', '이다', '있다', '입', '생각']\n",
    "\n",
    "\n",
    "# 키워드를 원형으로 변환하는 함수\n",
    "def lemmatize_keyword(keyword):\n",
    "    morphs = okt.pos(keyword, stem=True)  # 형태소 분석 + 어간 추출\n",
    "    # 품사가 명사(Noun)이거나 동사(Verb), 형용사(Adjective)인 경우만 원형으로 변환\n",
    "    lemmatized = [word for word, pos in morphs if pos in ['Noun', 'Verb', 'Adjective']]\n",
    "    return ' '.join(lemmatized)  # 원형 변환된 단어들을 문자열로 합침\n",
    "\n",
    "# 키워드와 유사도를 저장할 딕셔너리 초기화\n",
    "keyword_scores = defaultdict(float)\n",
    "\n",
    "# 키워드를 모두 모아서 유사도를 합산 (원형으로 변환하여 처리)\n",
    "for keywords in df['Keywords']:\n",
    "    for keyword, score in keywords:\n",
    "        lemmatized_keyword = lemmatize_keyword(keyword)  # 키워드 원형 변환\n",
    "        if lemmatized_keyword and lemmatized_keyword not in stop_words:  # 원형이 비어있지 않고 불용어가 아니라면\n",
    "            keyword_scores[lemmatized_keyword] += score  # 원형 키워드에 유사도 합산\n",
    "\n",
    "# 유사도가 높은 상위 10개 키워드 추출\n",
    "top_10_keywords_with_scores = sorted(keyword_scores.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "# 결과 출력\n",
    "print(top_10_keywords_with_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dab61ac-3919-4d5c-8643-de9235133895",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
